{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ataki adwersarialne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wstęp\n",
        "Jak pewnie słyszałaś/eś, sieci neuronowe są świetnym narzędziem do klasyfikacji obiektów, rozpoznawania złożonych zależności czy przewidywania przyszłych wartości na podstawie historycznych danych. Okazuje się, że są one przy tym podatne na ataki, które mogą znacząco osłabić ich działanie. Ataki te polegają na znalezieniu luki w rozumowaniu modelu. Załóżmy, że sieć nauczyła się rozpoznawać rower na zdjęciu. Spróbujmy inteligentnie zmodyfikować wybrane piksele z obszaru przedstawiającego rower tak, aby \"gołym okiem\" obrazek nadal przedstawiał rower. Zapytajmy sieć neuronową, czy nadal \"widzi\" rower na tak zmodyfikowanym obrazku. Jeżeli model nie zaklasyfikuje już obiektu jako rower, wówczas można stwierdzić, że **atak adwersarialny** się powiódł. **Atakiem adwersarialnym** nazywamy takie spreparowanie danych wejściowych, aby jak najskuteczniej zmylić sieć podczas podejmowania przez nią decyzji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zadanie\n",
        "Zaproponuj metodę włamania się do sieci neuronowej (ataku adwersarialnego), by obniżyć prawdopodobieństwo przypisania próbki do właściwej klasy, przy możliwie małych modyfikacjach testowanych obrazów. \n",
        "\n",
        "Naszym kryterium będzie iloczyn wartości `structural similarity index` ([SSIM](https://scikit-image.org/docs/stable/auto_examples/transform/plot_ssim.html)) uśrednionego po wszystkich obrazach biorących udział w ataku, z wartością różnicy pomiędzy początkową dokładnością modelu na danym zbiorze, a jego dokładnością na tym samym zbiorze poddanym modyfikacjom, zgodnie ze wzorem:  \n",
        "$$SSIM \\cdot (base_{acc} - final_{acc})$$\n",
        "gdzie:\n",
        "- $base_{acc}$ jest dokładnością klasyfikacji modelu na niezmodyfikowanym zbiorze testowym;\n",
        "- $final_{acc}$ jest dokładnością klasyfikacji modelu na zmodyfikowanym zbiorze.\n",
        "\n",
        "Powyższe kryterium i wszystkie wymagane do niego funkcje są zaimplementowane poniżej przez nas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ograniczenia\n",
        "- Twoje finalne rozwiązanie będzie testowane w środowisku z GPU.\n",
        "- Rozpatrywane będą wyłącznie rozwiązania, w których maksymalna odległość między pikselami oryginalnego obrazu a odpowiadającymi im pikselami po ataku adwersarialnym (w sensie wartości bezwzględnej) nie będzie większa niż $0.3$. Obrazy po atakach porównywane są do oryginalnych obrazów znormalizowanych do przedziału $<-1, 1>$.         \n",
        "  **PRZYKŁAD:** Wektory $[-1.0, 0.2, 0.5, -0.3]$ oraz $[-0.9, 0.1, 0.8, 0.0]$ są poprawne, ponieważ wektor różnic bezwzględnych pomiędzy nimi $[0.1, 0.1, 0.3, 0.3]$ nie zawiera elementów większych niż $0.3$. Natomiast wektory $[0.2, 0.5, -1.0, -0.4]$ oraz $[0.3, -0.9, -0.9, -0.6]$ już nie są poprawne, ponieważ drugie elementy obu wektorów różnią się od siebie o $1.4 > 0.3$.\n",
        "- Funkcja `perturbe_dataset()` ma przyjmować trójwymiarową tablicę typu Numpy o rozmiarze (liczba próbek x 28 x 28) i zwracać tablicę typu Numpy o rozmiarze (liczba próbek x 28 x 28), która będzie zbiorem po modyfikacji. Podczas tworzenia zmodyfikowanej wersji zbioru danych można korzystać z wszelkich informacji pochodzących z wytrenowanego modelu.\n",
        "- Twój atak powinien zostać przeprowadzony w maksymalnie 5 minut używając Google Colab z GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uwagi i wskazówki\n",
        "- Model został wytrenowany na zbiorze, w którym każdy z obrazów został z osobna znormalizowany do przedziału $<-1, 1>$, zarówno w zbiorze treningowym jak i walidacyjnym. Zbiór testowy, który nie jest dołączony do instrukcji zadania, będzie znormalizowany w analogiczny sposób.\n",
        "- Każdy obraz zbioru testowego będzie finalnie normalizowany do zakresu $<-1, 1>$, ale obrazy po modyfikacji, czyli na wyjściu funkcji `perturbe_dataset()`, będą jedynie przekształcane do postaci tensora i nie będą poddawane normalizacji.\n",
        "- Swoje rozwiązania możesz testować na zbiorze treningowym i walidacyjnym, ale punktacja za zadanie zostanie przyznana jedynie na podstawie wyniku na zbiorze testowym."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pliki zgłoszeniowe\n",
        " Tylko ten notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` będziesz mógł upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających. \n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 i 1 punktów. Zdobędziesz 0 punktów jeśli wartość kryterium na zbiorze testowym wyniesie poniżej 36.0, a 1 punkt jeśli wyniesie powyżej 42.0. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością kryterium."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "FINAL_EVALUATION_MODE = False \n",
        "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
        "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "X3pGyqgBn3uX"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "import os\n",
        "from copy import deepcopy\n",
        "\n",
        "import gdown\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ładowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    if not os.path.exists(f\"data\"):\n",
        "        gdown.download_folder(url=\"https://drive.google.com/drive/folders/1qmRd5O-LdOki1-HC4dgfaNrstzG3h_cN?usp=sharing\", output=f\"./data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Klasa zbioru danych\n",
        "class ContestDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = Image.fromarray(self.data[index])\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        y = self.labels[index]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Funkcja do normalizacji wartości pikseli do przedziału <-1, 1>\n",
        "def normalize_samples(samples):\n",
        "    assert len(samples.shape) == 3\n",
        "    samples = samples.reshape(-1, 28 * 28)\n",
        "    minimum_values = np.min(samples, axis=1)\n",
        "    maximum_values = np.max(samples, axis=1)\n",
        "\n",
        "    normalized_samples = (2 * (samples - minimum_values[:, np.newaxis]) / \\\n",
        "                          (maximum_values - minimum_values)[:, np.newaxis]) - 1\n",
        "    \n",
        "    normalized_samples = normalized_samples.reshape(\n",
        "        normalized_samples.shape[0], 28, 28\n",
        "    )\n",
        "    return normalized_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Wczytajmy potrzebne dane\n",
        "# X_train oraz y_train posłużą Ci do przygotowania ataku adwersarialnego\n",
        "# Na X_validation oraz y_validation sprawdzisz czy Twoje rozwiązanie przechodzi skrypt ewaluacyjny\n",
        "path_to_data = './data/'\n",
        "\n",
        "X_train = np.load(f'{path_to_data}contest_train_samples.npy') / 255.\n",
        "y_train = np.load(f'{path_to_data}contest_train_labels.npy')\n",
        "X_validation = np.load(f'{path_to_data}contest_validation_samples.npy') / 255.\n",
        "y_validation = np.load(f'{path_to_data}contest_validation_labels.npy')\n",
        "\n",
        "X_train = normalize_samples(X_train)\n",
        "X_validation = normalize_samples(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "validation_set = ContestDataset(X_validation,\n",
        "                                y_validation,\n",
        "                                transform=transforms.ToTensor())\n",
        "validation_loader = DataLoader(validation_set,\n",
        "                                batch_size=1,\n",
        "                                shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HI3Wo6SKoDpr"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Definicja klasyfikatora, który chcemy oszukać!\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 11 * 11, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "# Stwórzmy nasz klasyfikator\n",
        "net = Net()\n",
        "\n",
        "# Wczytajmy pretrenowane wagi do naszego modelu\n",
        "net.load_state_dict(torch.load('trained_model.pth',\n",
        "                               map_location=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kod z kryteriami oceniającymi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "def evaluate_network(data_loader,\n",
        "                     model,\n",
        "                     device,\n",
        "                     verbose=True):\n",
        "    # Dokonajmy ewaluacji wytrenowanego modelu na wybranym zbiorze\n",
        "    all_predictions, all_labels = [], []\n",
        "    model.to(device)\n",
        "    # Sieć neuronowa musi zostać przeniesiona do trybu ewaluacji\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            # Wybieramy klasę o najwyższym prawdopodobieństwie przynależności\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_predictions.append(predicted.ravel())\n",
        "            all_labels.append(labels.ravel())\n",
        "    all_predictions = torch.cat(all_predictions, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "    # Sprawdzamy, ile etykiet zostało prawidłowo wytypowanych przez sieć\n",
        "    correct = (all_predictions == all_labels).sum().item()\n",
        "    accuracy = (100 * correct / all_labels.size()[0])\n",
        "    no_of_elements = len(data_loader.dataset)\n",
        "    if verbose:\n",
        "        print(f'Dokładność klasyfikacji na {no_of_elements} obrazów wybranego zbioru wynosi '\n",
        "              f'{accuracy} %.')\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Funkcja do wyliczenia SSIM oraz maksymalnej odległości między odpowiadającymi pikselami\n",
        "def calculate_similarity(original_dataset,\n",
        "                         perturbed_dataset):\n",
        "    # Zarówno original_dataset jak i perturbed_dataset mają być typu Numpy array.\n",
        "    # Mają mieć taki sam rozmiar, tj. (liczba elementów x 28 x 28)\n",
        "    assert original_dataset.shape == perturbed_dataset.shape\n",
        "    assert original_dataset.shape[1] == original_dataset.shape[2] == 28\n",
        "    assert perturbed_dataset.shape[1] == perturbed_dataset.shape[2] == 28\n",
        "    similarities, L1_distances = [], []\n",
        "    for i in range(original_dataset.shape[0]):\n",
        "        original_element = original_dataset[i].ravel()\n",
        "        perturbed_element = perturbed_dataset[i].ravel()\n",
        "        similarities.append(\n",
        "            ssim(\n",
        "                original_element,\n",
        "                perturbed_element,\n",
        "                data_range=2)\n",
        "            )\n",
        "        L1_distances.append(\n",
        "            np.max(np.abs(\n",
        "                original_element - perturbed_element\n",
        "            ))\n",
        "        )\n",
        "    mean_SSIM = np.mean(similarities)\n",
        "    max_distance = np.max(L1_distances)\n",
        "    print(f'Średnia wartość SSIM wynosi {mean_SSIM}, a największa odległość między pikselami wynosi: {max_distance}.')\n",
        "    return mean_SSIM, max_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    result = evaluate_network(\n",
        "        validation_loader,\n",
        "        net,\n",
        "        device,\n",
        "        verbose=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twoje rozwiązanie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To jest jedyna sekcja, w której musisz coś zrobić."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hubert Jastrzębski - V LO Kraków\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMvfkZOUZzPj",
        "outputId": "5f957a50-0b7e-432e-9978-ad1d32ec61a1"
      },
      "outputs": [],
      "source": [
        "net.to(device)\n",
        "\n",
        "\n",
        "def perturbe_dataset(original_dataset):\n",
        "    \"\"\"\n",
        "    To tutaj masz przygotować funkcję do zaburzania zbioru danych. Na wejściu ma znajdować\n",
        "    się tablica typu Numpy array o rozmiarze (liczba elementów, 28, 28). Podobnie ma być na\n",
        "    wyjściu. A co wydarzy się po drodze? To już zależy od Ciebie i Twojej pomysłowości!\n",
        "    \"\"\"\n",
        "    assert len(original_dataset.shape) == 3\n",
        "    \n",
        "    perturbed_dataset = deepcopy(original_dataset)\n",
        "    epsilon = .29\n",
        "\n",
        "    for i, image in enumerate(perturbed_dataset): \n",
        "        image_tensor = torch.tensor(image, dtype=torch.float32, device=device)[None, None, :, :]\n",
        "        output = net(image_tensor)\n",
        "        target = output.max(1)[1]\n",
        "\n",
        "        delta = torch.zeros_like(image_tensor, requires_grad=True, device=device)\n",
        "        opt = optim.NAdam([delta], lr=0.05)\n",
        "\n",
        "        is_ok = False\n",
        "        \n",
        "        for epoch in range(5):\n",
        "            pred = net(image_tensor + delta)\n",
        "            new_target = pred.max(1)[1]\n",
        "            if new_target != target:\n",
        "                is_ok = True\n",
        "                break\n",
        "\n",
        "            loss = -nn.CrossEntropyLoss()(pred, target)\n",
        "            #print(epoch, loss.item())\n",
        "            \n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            \n",
        "            delta.data.clamp_(-epsilon, epsilon)\n",
        "        \n",
        "        if is_ok:\n",
        "            perturbed_dataset[i] = torch.clamp(image_tensor + delta, -1, 1).detach().cpu()\n",
        "    \n",
        "    \n",
        "    assert len(perturbed_dataset.shape) == 3\n",
        "    assert perturbed_dataset.shape[1] == 28\n",
        "    assert perturbed_dataset.shape[2] == 28\n",
        "    return perturbed_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ewaluacja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Poniższy kod będzie służył ewaluacji rozwiązania. Po wysłaniu rozwiązania do nas zostanie wykonana funkcja `evaluate_algorithm(net, X_validation, y_validation, device, perturbe_dataset)`, t.j. prawie identyczny kod jak niżej będzie się uruchamiał na katalogu zdjęć `test_data` dostępnym tylko dla sprawdzających zadania.\n",
        "\n",
        "Upewnij się przed wysłaniem, że cały notebook wykonuje się od początku do końca bez błędów i bez ingerencji użytkownika po wykonaniu polecenia `Run All`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_algorithm(model, images, labels, device, perturbe_algorithm):\n",
        "    dataset_for_perturbation = deepcopy(images)\n",
        "    dataset_attacked = perturbe_algorithm(dataset_for_perturbation)\n",
        "\n",
        "    SSIM, distance = calculate_similarity(\n",
        "        dataset_for_perturbation,\n",
        "        dataset_attacked\n",
        "    )\n",
        "    assert distance <= 0.3\n",
        "\n",
        "    perturbed_set = ContestDataset(dataset_attacked,\n",
        "                                labels,\n",
        "                                transform=transforms.ToTensor())\n",
        "    perturbed_loader = DataLoader(perturbed_set,\n",
        "                                batch_size=64,\n",
        "                                shuffle=False)\n",
        "    perturbed_accuracy = evaluate_network(\n",
        "        perturbed_loader,\n",
        "        model,\n",
        "        device,\n",
        "        verbose=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not FINAL_EVALUATION_MODE:\n",
        "    evaluate_algorithm(net, X_validation, y_validation, device, perturbe_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
