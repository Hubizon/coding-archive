{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2szhiq0QJ4Ek"
      },
      "source": [
        "# Śledzenie obiektów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wstęp\n",
        "W erze cyfrowej, w obliczu rosnącej lawinowo ilości danych wideo, zdolność do ich automatycznego rozpoznawania i interpretowania staje się kluczowa w wielu dziedzinach – od bezpieczeństwa publicznego po autonomiczne pojazdy. Technologie oparte na głębokim uczeniu rewolucjonizują sposób, w jaki przetwarzamy informacje wizualne. Kluczowym wyzwaniem jest tu detekcja i śledzenie obiektów na filmach wideo.\n",
        "\n",
        "Celem tego zadania jest opracowanie algorytmu, który będzie w stanie analizować sekwencje ruchów w grze \"trzy kubki\". Uczestnicy mają za zadanie określić końcową pozycję kubków po serii ruchów, korzystając z analizy statycznych obrazów z każdej klatki nagrania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "# Poniższe funkcje ułatwiają pracę z dostarczonymi danymi\n",
        "# W kolejnych komórkach zobaczysz przykłady ich użycia\n",
        "from utils.utils import get_level_info, get_video_data, display_video, download_and_replace_data\n",
        "\n",
        "FINAL_EVALUATION_MODE = False\n",
        "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
        "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!\n",
        "\n",
        "images, coordinates, _, path_to_images = get_video_data(level=3,video_id=0,dataset=\"example\")\n",
        "display_video(images,rescale=0.7,FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zadanie 3: Zbuduj rozwiązanie od zera\n",
        "\n",
        "W tym zadaniu podejdziesz do problemu identyfikacji obiektów na filmach wideo od podstaw. Poprzednie zadania wymagały użycia gotowych informacji o lokalizacji obiektów w klatkach. Tym razem będziesz musiał stworzyć algorytm, który będzie operować bezpośrednio na nieoznaczonych obrazach, co pozwoli na pełniejsze zrozumienie i opracowanie własnego systemu detekcji obiektów.\n",
        "\n",
        "Napisz algorytm, który poradzi sobie ze zbiorem danych `level_3` bez podanych prostokątów ograniczających.\n",
        "\n",
        "## Pliki zgłoszeniowe\n",
        "Tylko ten notebook zawierający **kod** oraz **krótki raport** opisujący Twoje rozwiązanie (do 300 słów). Miejsce na raport znajdziesz na końcu tego notebooka.\n",
        "\n",
        "## Ograniczenia\n",
        "- Twoja funkcja powinna zwracać predykcje w maksymalnie 5 minut używając Google Colab bez GPU.\n",
        "\n",
        "## Uwagi i wskazówki\n",
        "- Testuj swoje rozwiązanie na zbiorze plików wideo `level_3`.\n",
        "- **Skuteczność modelu**: przetestuj skuteczność modelu na zbiorze walidacyjnym używając dostarczonej przez nas funkcji **submission_script**, umieść ten wynik w raporcie.\n",
        "\n",
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` możesz upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających.\n",
        "\n",
        "Za to podzadanie możesz zdobyć pomiędzy 0 i 0.5 punktów. Zdobędziesz 0 punktów jeśli Twoje accuracy na zbiorze testowym będzie poniżej 30%. Jeśli będzie równe 100%, otrzymasz 0.5 punktu. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością metryki."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Poniższe biblioteki są wystarczające do wykonania wszystkich zadań\n",
        "# Jeśli jednak chcesz użyć innych, sprawdź czy są dostępne na serwerze (requirements.txt)\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import IPython.display\n",
        "import json\n",
        "import PIL\n",
        "import sklearn as sk\n",
        "import gdown\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# funkcja pomocnicza do ładowania danych\n",
        "images, _, _, _ = get_video_data(level=3,video_id=0,dataset=\"example\")\n",
        "\n",
        "with open(os.path.join(os.getcwd(),'example_tracks','tracks_3_0.json'), 'r') as f:\n",
        "    tracks = json.load(f)\n",
        "\n",
        "for key in tracks.keys():\n",
        "    tracks[key] = [tuple(el) for el in tracks[key]]\n",
        "\n",
        "# funkcja pomocnicza do wyświetlania danych\n",
        "display_video(images,\n",
        "                tracks=tracks,\n",
        "                rescale=0.7,\n",
        "                FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pobieranie danych do podzadań 1, 2 i 3 (około ~646Mb), skrypt będzie wykonywał się parę minut\n",
        "# Wystarczy, że pobierzesz dane tylko raz. Na serwerze sprawdzającym dane będą już pobrane,\n",
        "# struktura plików będzie identyczna jak tutaj\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    download_and_replace_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# funkcja pomocnicza do testowania algorytmu\n",
        "# Zwróć uwagę na to że funkcja ta działa inaczej niż w poprzednich podzadaniach\n",
        "# algorytm przyjmuje jako argument listę obrazków, a nie koordynaty\n",
        "def submission_script(algorithm,level,verbose=False,dataset=\"valid\"):\n",
        "    num_videos, _ = get_level_info(level=level,dataset=dataset)\n",
        "    correct = []\n",
        "    exception_messages = set()\n",
        "    for video_number in range(num_videos):\n",
        "        images, _, target, _ = get_video_data(level=level,video_id=video_number,dataset=dataset)\n",
        "        try:\n",
        "            prediction = algorithm(images)\n",
        "            if tuple(target) == tuple(prediction):\n",
        "                correct.append(1)\n",
        "            else:\n",
        "                correct.append(0)\n",
        "            if verbose:\n",
        "                print(f\"Video: animation_{str(video_number).zfill(4)}\")\n",
        "                print(f\"Prediction: {prediction}\")\n",
        "                print(f\"Target:     {target}\")\n",
        "                print(f\"Score: {tuple(target) == tuple(prediction)}\", end='\\n\\n')\n",
        "        except Exception as e:\n",
        "            correct.append(0)\n",
        "            exception_messages.add(str(e))\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {np.mean(correct)}\")\n",
        "        print(f\"Correctness: {correct}\")\n",
        "    return np.sum(correct) / num_videos, correct, exception_messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twoje rozwiązanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hubert Jastrzębski - V LO Kraków\n",
        "\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from itertools import permutations \n",
        "from statistics import median\n",
        "from copy import deepcopy, copy\n",
        "import math\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_points(images): # nie zmieniaj nazwy funkcji\n",
        "    points = np.array([])\n",
        "\n",
        "    prev_clusters = [[155, 255], [210, 320], [290, 465]]\n",
        "    for i in range(len(images)):\n",
        "        coors = np.argwhere(np.array(images[i])[:,:,1] == 0)\n",
        "\n",
        "        m_iter = (10 if i == 0 else 1)\n",
        "        kmeans = KMeans(n_clusters=3, init=prev_clusters, max_iter=m_iter, n_init=1).fit(coors)\n",
        "        points = np.append(points, kmeans.cluster_centers_)\n",
        "\n",
        "        prev_clusters = kmeans.cluster_centers_\n",
        "\n",
        "    points = points.reshape((-1, 3, 2))\n",
        "    return points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distance(a, b):\n",
        "    return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
        "\n",
        "def your_algorithm_task_3(images): # nie zmieniaj nazwy funkcji\n",
        "    points = get_points(images)\n",
        "    \n",
        "    indices_p = np.argsort(points[0][:, 0])\n",
        "    points[0] = points[0][indices_p]\n",
        "\n",
        "    for i in range(1, len(points)):\n",
        "        p = copy(points[i])\n",
        "        best_perm = [0, 1, 2]\n",
        "        best_dist = math.inf\n",
        "        \n",
        "        for perm in list(permutations([0, 1, 2])):\n",
        "            p_temp = [p[j] for j in perm]\n",
        "            dist = sum(distance(points[i - 1][j], p_temp[j]) for j in [0, 1, 2])\n",
        "\n",
        "            if dist < best_dist:\n",
        "                best_dist = dist\n",
        "                best_perm = perm\n",
        "\n",
        "        points[i] = [points[i][j] for j in best_perm]\n",
        "\n",
        "    rp = [points[-1][i][0] for i in [0, 1, 2]]\n",
        "    res = [rp.index(i) for i in [min(rp), median(rp), max(rp)]]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sprawdź jak działa Twój algorytm\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    accuracy, correctness, _ = submission_script(\n",
        "        algorithm=your_algorithm_task_3,\n",
        "        level=3,\n",
        "        verbose=True,\n",
        "        dataset=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zapisz swój raport do zmiennej poniżej, abyśmy mogli go później automatycznie odczytać sprawdzaczką\n",
        "raport_3 = \\\n",
        "\"\"\"\n",
        "Raport z zadania:\n",
        "znajduję czerwone piksele\n",
        "używam algorytmu klasteryzacji do znalezienie trzech środków tych obiektów w każdej klatce\n",
        "rozpatruję po kolei klatki\n",
        "dla każdej klatki patrzę która permutacja środków daje najmniejszą sumę odległości \n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
