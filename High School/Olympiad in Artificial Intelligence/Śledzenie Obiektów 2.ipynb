{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2szhiq0QJ4Ek"
      },
      "source": [
        "# Śledzenie obiektów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wstęp\n",
        "W erze cyfrowej, w obliczu rosnącej lawinowo ilości danych wideo, zdolność do ich automatycznego rozpoznawania i interpretowania staje się kluczowa w wielu dziedzinach – od bezpieczeństwa publicznego po autonomiczne pojazdy. Technologie oparte na głębokim uczeniu rewolucjonizują sposób, w jaki przetwarzamy informacje wizualne. Kluczowym wyzwaniem jest tu detekcja i śledzenie obiektów na filmach wideo.\n",
        "\n",
        "Celem tego zadania jest opracowanie algorytmu, który będzie w stanie analizować sekwencje ruchów w grze \"trzy kubki\". Uczestnicy mają za zadanie określić końcową pozycję kubków po serii ruchów, korzystając z analizy statycznych obrazów z każdej klatki nagrania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "# Poniższe funkcje ułatwiają pracę z dostarczonymi danymi\n",
        "# W kolejnych komórkach zobaczysz przykłady ich użycia\n",
        "from utils.utils import get_level_info, get_video_data, display_video, download_and_replace_data\n",
        "\n",
        "FINAL_EVALUATION_MODE = False\n",
        "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
        "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!\n",
        "\n",
        "images, coordinates, target, path_to_images = get_video_data(level=2,video_id=0,dataset=\"example\")\n",
        "display_video(images,rescale=0.7,FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zadanie 2: Okluzje, rozmycia, przesłonienie\n",
        "\n",
        "Celem zadania jest opracowanie algorytmu, który potrafi przetwarzać sekwencje obrazów z gry w trzy kubki, nawet gdy występują rozmycia czy przesłonięcia. Zadanie ma na celu nauczenie maszyny wykorzystywania ciągłości informacji z kolejnych klatek, aby mimo chwilowych utrudnień w percepcji, mogła skutecznie określić końcową pozycję kubków.\n",
        "\n",
        "Napisz algorytm który poradzi sobie z trudnieszym zbiorem danych - `Level_2`. Składa się on z animacji, w których pojawiają się dodatkowe utrudnienia:\n",
        "- Przesłonięcia obiektu przez inny, powodujące, że są one traktowane jako jeden,\n",
        "- Prostokąty ograniczające nie są już idealnie dopasowane do obiektów,\n",
        "- Prostokąty ograniczające nie są widoczne we wszystkich klatkach.\n",
        "\n",
        "Będziesz miał dostęp zarówno do wszystkich klatek animacji, jak i do oznaczonych przez nas prostokątów ograniczających, w których znajdują się kubki. Co ważne, algorytm, który będziesz tworzył ma korzystać jedynie z informacji o prostokątach ograniczających. W tym zadaniu, klatki wideo są dostarczone jedynie do wizualizacji przykładów i algorytmu, na własne potrzeby.\n",
        "\n",
        "Punkty za to zadanie będą przyznane za osiągnięcie jak najdokładniejszych predykcji na zbiorze testowym. Kryterium będzie *accuracy* i spodziewamy się wyników powyżej `80%`. Ewaluacja na zbiorze testowym będzie dokonana przez organizatorów.\n",
        "\n",
        "## Pliki zgłoszeniowe\n",
        "Tylko ten notebook zawierający **kod** oraz **krótki raport** opisujący Twoje rozwiązanie (do 300 słów). Miejsce na raport znajdziesz na końcu tego notebooka.\n",
        "\n",
        "## Ograniczenia\n",
        "- Twoja funkcja powinna zwracać predykcje w maksymalnie 5 minut używając Google Colab bez GPU.\n",
        "\n",
        "## Uwagi i wskazówki\n",
        "- Testuj swoje rozwiązanie na zbiorze plików wideo `level_2`.\n",
        "- **Skuteczność modelu**: przetestuj skuteczność modelu na zbiorze walidacyjnym używając dostarczonej przez nas funkcji **submission_script**, umieść ten wynik w raporcie.\n",
        "\n",
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` możesz upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających.\n",
        "\n",
        "Za to podzadanie możesz zdobyć pomiędzy 0 i 0.5 punktów. Zdobędziesz 0 punktów jeśli Twoje accuracy na zbiorze testowym będzie poniżej 50%. Jeśli będzie większe niż 95%, otrzymasz 0.5 punktu. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością metryki."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Poniższe biblioteki są wystarczające do wykonania wszystkich zadań\n",
        "# Jeśli jednak chcesz użyć innych, sprawdź czy są dostępne na serwerze (requirements.txt)\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import IPython.display\n",
        "import json\n",
        "import PIL\n",
        "import sklearn as sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# funkcja pomocnicza do ładowania danych\n",
        "images, _, _, _ = get_video_data(level=2,video_id=0,dataset=\"example\")\n",
        "\n",
        "with open(os.path.join(os.getcwd(),'example_tracks','tracks_2_0.json'), 'r') as f:\n",
        "    tracks = json.load(f)\n",
        "\n",
        "for key in tracks.keys():\n",
        "    tracks[key] = [tuple(el) for el in tracks[key]]\n",
        "\n",
        "# funkcja pomocnicza do wyświetlania danych\n",
        "display_video(images,\n",
        "                tracks=tracks,\n",
        "                rescale=0.7,\n",
        "                FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pobieranie danych do podzadań 1, 2 i 3 (około ~646Mb), skrypt będzie wykonywał się parę minut\n",
        "# Wystarczy, że pobierzesz dane tylko raz. Na serwerze sprawdzającym dane będą już pobrane,\n",
        "# struktura plików będzie identyczna jak tutaj\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    download_and_replace_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# funkcja pomocnicza do testowania algorytmu\n",
        "def submission_script(algorithm,level,verbose=False,dataset=\"valid\"):\n",
        "    num_videos, _ = get_level_info(level=level,dataset=dataset)\n",
        "    correct = []\n",
        "    exception_messages = set()\n",
        "    for video_number in range(num_videos):\n",
        "        _, coordinates, target, _ = get_video_data(level=level,video_id=video_number,dataset=dataset)\n",
        "        try:\n",
        "            prediction = algorithm(coordinates)\n",
        "            if tuple(target) == tuple(prediction):\n",
        "                correct.append(1)\n",
        "            else:\n",
        "                correct.append(0)\n",
        "            if verbose:\n",
        "                print(f\"Video: animation_{str(video_number).zfill(4)}\")\n",
        "                print(f\"Prediction: {prediction}\")\n",
        "                print(f\"Target:     {target}\")\n",
        "                print(f\"Score: {tuple(target) == tuple(prediction)}\", end='\\n\\n')\n",
        "        except Exception as e:\n",
        "            correct.append(0)\n",
        "            exception_messages.add(str(e))\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {np.mean(correct)}\")\n",
        "        print(f\"Correctness: {correct}\")\n",
        "    return np.sum(correct) / num_videos, correct, exception_messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twoje rozwiązanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hubert Jastrzębski - V LO Kraków\n",
        "\n",
        "from itertools import permutations \n",
        "from statistics import median\n",
        "from copy import deepcopy\n",
        "import math\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getPerspectiveTransform(sourcePoints, destinationPoints):\n",
        "    a = np.zeros((8, 8))\n",
        "    b = np.zeros((8))\n",
        "    for i in range(4):\n",
        "        a[i][0] = a[i+4][3] = sourcePoints[i][0]\n",
        "        a[i][1] = a[i+4][4] = sourcePoints[i][1]\n",
        "        a[i][2] = a[i+4][5] = 1\n",
        "        a[i][3] = a[i][4] = a[i][5] = 0\n",
        "        a[i+4][0] = a[i+4][1] = a[i+4][2] = 0\n",
        "        a[i][6] = -sourcePoints[i][0]*destinationPoints[i][0]\n",
        "        a[i][7] = -sourcePoints[i][1]*destinationPoints[i][0]\n",
        "        a[i+4][6] = -sourcePoints[i][0]*destinationPoints[i][1]\n",
        "        a[i+4][7] = -sourcePoints[i][1]*destinationPoints[i][1]\n",
        "        b[i] = destinationPoints[i][0]\n",
        "        b[i+4] = destinationPoints[i][1]\n",
        "\n",
        "    x = np.linalg.solve(a, b)\n",
        "    x.resize((9,), refcheck=False)\n",
        "    x[8] = 1\n",
        "    return x.reshape((3,3))\n",
        "\n",
        "original_points = np.float32([[320, 240], [150, 130], [320, 85], [490, 130]])\n",
        "\n",
        "top_view_points = np.float32([[0, 0], [0, 1000], [1000, 1000], [1000, 0]])\n",
        "matrix = getPerspectiveTransform(original_points, top_view_points)\n",
        "\n",
        "def transform_point(p):\n",
        "  px = (matrix[0][0]*p[0] + matrix[0][1]*p[1] + matrix[0][2]) / ((matrix[2][0]*p[0] + matrix[2][1]*p[1] + matrix[2][2]))\n",
        "  py = (matrix[1][0]*p[0] + matrix[1][1]*p[1] + matrix[1][2]) / ((matrix[2][0]*p[0] + matrix[2][1]*p[1] + matrix[2][2]))\n",
        "  return (px, py)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distance(a, b):\n",
        "    return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
        "\n",
        "def your_algorithm_task_2(coordinates): # nie zmieniaj nazwy funkcji\n",
        "    points = [[((xa + xb) / 2, (ya + yb) / 2) for (xa, ya, xb, yb) in coordinates[name]] for name in coordinates]\n",
        "    (b1, res1) = subtask(points)\n",
        "\n",
        "    new_points = []\n",
        "    for i in range(len(points)) :\n",
        "        new_points.append(points[len(points)-i-1])\n",
        "\n",
        "    (b2, res2) = subtask(new_points)\n",
        "\n",
        "    if (b1 < b2 * 1.008): \n",
        "        return res1\n",
        "    return res2\n",
        "\n",
        "def subtask(points): \n",
        "    points = [[transform_point(p) for p in ps] for ps in points] \n",
        "    points = [[(round(q[0], 1), round(q[1], 1)) for q in p] for p in points]\n",
        "\n",
        "    points[0].sort()\n",
        "    velocity = [[0, 0, 0]]\n",
        "    max_velocity = 0\n",
        "    \n",
        "    sum_best_p = 0\n",
        "    best_res = 0\n",
        "    for i in range(1, len(points)):\n",
        "        p = deepcopy(points[i])\n",
        "        best_res = 0\n",
        "        if len(p) == 0:\n",
        "            points[i] = deepcopy(points[i - 1])\n",
        "        \n",
        "        elif len(p) == 1:\n",
        "            best_res = math.inf\n",
        "            best_j = 0\n",
        "            for j in [0, 1, 2]:\n",
        "                points[i] = deepcopy(points[i - 1])\n",
        "                points[i][j] = deepcopy(p[0])\n",
        "                res = (distance(points[i][j], points[i - 1][j]))\n",
        "\n",
        "                if res < best_res:\n",
        "                    best_res = res \n",
        "                    best_j = j\n",
        "\n",
        "            points[i] = deepcopy(points[i - 1])\n",
        "            points[i][best_j] = deepcopy(p[0])\n",
        "\n",
        "\n",
        "        elif len(p) == 2:\n",
        "            best_res = math.inf\n",
        "            best_p = deepcopy(points[i - 1])\n",
        "            for perm in permutations([0, 1, 2], 2):\n",
        "                points[i] = deepcopy(points[i - 1])\n",
        "                points[i][perm[0]] = deepcopy(p[0])\n",
        "                points[i][perm[1]] = deepcopy(p[1])\n",
        "                r = [(distance(points[i][j], points[i - 1][j])) for j in [0, 1, 2]]\n",
        "                mv = min(velocity[i-1])\n",
        "                res = sum(r)\n",
        "\n",
        "                if res < best_res:\n",
        "                    best_res = res \n",
        "                    best_p = deepcopy(points[i])\n",
        "\n",
        "            points[i] = best_p\n",
        "\n",
        "        elif len(p) == 3:\n",
        "            best_res = math.inf\n",
        "            best_p = deepcopy(points[i - 1])\n",
        "            for perm in permutations([0, 1, 2]):\n",
        "                points[i] = [p[j] for j in perm]\n",
        "                r = [(distance(points[i][j], points[i - 1][j])) for j in [0, 1, 2]]\n",
        "\n",
        "                res = sum(r)\n",
        "                \n",
        "                if res < best_res:\n",
        "                    best_res = res \n",
        "                    best_p = deepcopy(points[i])\n",
        "            points[i] = best_p\n",
        "            \n",
        "        if i > 0 :\n",
        "            v = [distance(points[i][j], points[i-min(i,3)][j])/min(i,3) for j in range(3)]\n",
        "            velocity.append(v)\n",
        "            max_velocity = max(max_velocity, max(velocity[i]))\n",
        "        sum_best_p += best_res\n",
        "        \n",
        "    rp = [points[-1][i][0] for i in [0, 1, 2]]\n",
        "    res = [rp.index(i) for i in [min(rp), median(rp), max(rp)]]\n",
        "\n",
        "    return (sum_best_p, res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sprawdź jak działa Twój algorytm\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    accuracy, correctness, _ = submission_script(\n",
        "        algorithm=your_algorithm_task_2,\n",
        "        level=2,\n",
        "        verbose=True,\n",
        "        dataset=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zapisz swój raport do zmiennej poniżej, abyśmy mogli go później automatycznie odczytać sprawdzaczką\n",
        "raport_2 = \\\n",
        "\"\"\"\n",
        "Raport z zadania:\n",
        "zamieniam współrzędne prostokątów na ich środki\n",
        "transformuję te punkty na takie trochę bardziej z góry\n",
        "rozpatruję po kolei klatki\n",
        "dla każdej klatki patrzę która permutacja środków daje najmniejszą sumę odległości\n",
        "(jeśli niektóre środki zniknęły, to zostawiam je takie same jak w poprzedniej klatce)\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
