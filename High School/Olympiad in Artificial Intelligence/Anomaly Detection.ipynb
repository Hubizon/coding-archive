{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS4H9K4M6UOy"
      },
      "source": [
        "# Detekcja anomalii"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiMm7U437d9d"
      },
      "source": [
        "Detekcja anomalii jest zagadnieniem, które często jest realizowane w zastosowaniach biznesowych. Jednym z takich przykładów jest analiza jakości wytwarzanych produktów na linii produkcyjnej, gdzie większość produktów jest wytworzona prawidłowo (spełnia normy), a pewna niewielka liczba próbek jest wadliwa. Innym przykładem zagadnienia detekcji anomalii są systemy analizujące ruch sieciowy, a celem jest wykrycie zdarzeń odstających, np. w postaci ataków DDoS.\n",
        "\n",
        "Zagadnienie detekcji anomalii można więc sformalizować jako znalezienie próbek/zdarzeń odstających (ang. *outliers*), które zazwyczaj pojawiają się rzadko w zbiorze. Można powiedzieć, że w zbiorze jest wiele ,,typowych\" próbek, pochodzących z pewnego rozkładu danych, a celem jest znalezienie nielicznych próbek pochodzących spoza tego rozkładu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai6ynuAO9OSD"
      },
      "source": [
        "## Zadanie\n",
        "Na podstawie dostarczonego zbioru danych, zaproponuj algorytm typu *self-supervised* (częściowo nadzorowany) lub *unsupervised* (nienadzorowany) do detekcji anomalii. Są one oznaczone etykietą `1`. Próbki zawierające normalne obserwacje są oznaczone etykietą `0`. **W swoim rozwiązaniu wykorzystaj sieć neuronową**. Finalnie Twoje rozwiązanie powinno przypisać wartość dwóch zmiennych globalnych:\n",
        "- `BATCH_SIZE` - rozmiaru serii danych na jakich operowały będą dataloader'y. Podczas sprawdzania wczytamy tę wartość i użyjemy do dataloder'u z danymi testowymi.\n",
        "- `model` - przygotowany model, który będzie składał się z funkcji `forward()` tradycyjnie wykorzystywanej do propagacji danych przez sieć, a także z funkcji `predict()`, która ma dokonywać ostatecznego przyporządkowania danej próbki do jednej z klas: `0` lub `1`. Zmienna `model` musi być wytrenowaną instancją klasy `Model`. `model` zostanie użyty do ewaluacji rozwiązania na zbiorze testowym.\n",
        "\n",
        "**UWAGA: Model można trenować tylko na zbiorze treningowym, który zawiera jedynie normalne obserwacje.**\n",
        "\n",
        "**UWAGA: Nazwy zmiennych oraz sygnatura funkcji** `predict` **musi zostać niezmieniona - możesz użyć sprawdzaczki w celu weryfikacji tych wymagań.**\n",
        "\n",
        "## Ocenianie\n",
        "Po wytrenowaniu przygotowanego przez Ciebie modelu, do oceny rozwiązania wywoływana będzie metoda `predict()`. Ma ona zawierać mechanizm przyporządkowania otrzymanej na wejściu próbki danych na podstawie wyjścia modelu i potencjalnych dodatkowych, przygotowanych przez Ciebie kryteriów oceny predykcji modelu.\n",
        "Jakość zaproponowanego rozwiązania będzie wyznaczona poprzez wyliczenie dokładnosci klasyfikacji (ang. *accuracy*) na zbiorze testowym, który dostępny jest dla organizatorów. Zbiór testowy jest **zbalansowany**, a obrazki w nim cechują się takimi samymi charakterystykami, jak te dostarczone uczestnikom.\n",
        "\n",
        "Model osiągający dokładność klasyfikacji poniżej 60% otrzyma 0 punktów, powyżej 90% 1 punkt a wartości pośrednie będą liniowo skalowane w tym zakresie. Finalny wynik uczestnika będzie oceniany na podstawie wzoru poniżej:\n",
        "$$\n",
        "score = min(max(accuracy - 0.6, 0.0), 0.3) / 0.3\n",
        "$$\n",
        "\n",
        "gdzie $\\mathrm{accuracy} \\in [0, 1]$ jest dokładnością klasyfikacji na zbiorze testowym."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jww7kRgHNItR"
      },
      "source": [
        "## Pliki zgłoszeniowe\n",
        "1. Tylko ten notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_M0jz3aNQ69"
      },
      "source": [
        "## Ograniczenia\n",
        "- Ewaluacja twojego rozwiązania (wraz z treningiem sieci neuronowej, flaga `FINAL_EVALUATION_MODE` ustawiona na `True`) na 10 000 przykładach testowych powinna trwać nie dłużej niż 15 minut na Google Colab **z** GPU.\n",
        "\n",
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`.\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 i 1 punktów. Liczba punktów, które zdobędziesz będzie równa wartości `score`, wyliczonej na zbiorze testowym."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk2dAa-7N0cW"
      },
      "source": [
        "# Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LYWQciqWwEHd"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "FINAL_EVALUATION_MODE = False\n",
        "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
        "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxBGT0hMEqrT",
        "outputId": "b0178b45-9e23-4b88-acb1-fe3f9d7f2111"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "import random\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S5QngBh41y2O"
      },
      "outputs": [],
      "source": [
        "if not FINAL_EVALUATION_MODE:\n",
        "    ! gdown https://drive.google.com/uc?id=1QoTW4eZctWvzmjrNrwmai9zhL8RWnhBU\n",
        "    # ! gdown https://drive.google.com/uc?id=1bD38bZf8pcUyinuvYDXO56RPlXUluzxn\n",
        "    # ! gdown https://drive.google.com/uc?id=108d2ERztZzq5_ZXyizxeWDOCctG5xhIy\n",
        "\n",
        "    ! unzip anomaly.zip\n",
        "    ! unzip train.zip\n",
        "    ! unzip valid.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9vc1AR3EoJd"
      },
      "source": [
        "## Ładowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hBiqafIyyofN"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "TRAIN_DIR: Path = Path(\"./train\")\n",
        "VALID_DIR: Path = Path(\"./valid\")\n",
        "\n",
        "TRAIN_CSV: Path = Path(\"./train.csv\")\n",
        "VALID_CSV: Path = Path(\"./valid.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J7p-Qyi88hZN"
      },
      "outputs": [],
      "source": [
        "# Ustaw swój batch size -- będziemy wymagać obecności tej zmiennej podczas sprawdzania i użyjemy jej podczas testów\n",
        "BATCH_SIZE: int = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tU5wo3TX2D2I"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, dir: Path, csv: Path):\n",
        "        self.dir: Path = dir\n",
        "        self.csv = pd.read_csv(csv)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.csv)\n",
        "\n",
        "    def __getitem__(self, idx) -> tuple[torch.Tensor, int]:\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        path, label = self.csv.iloc[idx]\n",
        "        img = plt.imread(self.dir / path)\n",
        "\n",
        "        to_tensor = transforms.ToTensor()\n",
        "        return to_tensor(img), label\n",
        "\n",
        "\n",
        "def train_dataloader() -> DataLoader:\n",
        "    \"\"\"Stwórz Dataloader z danymi treningowymi.\"\"\"\n",
        "    return DataLoader(ImageDataset(TRAIN_DIR, TRAIN_CSV), batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "def valid_dataloader() -> DataLoader:\n",
        "    \"\"\"Stwórz Dataloader z danymi walidacyjnymi.\"\"\"\n",
        "    return DataLoader(ImageDataset(VALID_DIR, VALID_CSV), batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZAxjOjR44Al"
      },
      "source": [
        "# Przykładowy szkielet rozwiązania + naiwne rozwiązanie\n",
        "\n",
        "Poniżej prezentujemy proste rozwiązanie, które w oczywisty sposób nie jest optymalne. Służy temu, aby było wiadomo w jaki sposób ma działać cały notatnik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YkvTI1w_d_FK"
      },
      "outputs": [],
      "source": [
        "# Hubert Jastrzębski\n",
        "# V LO Kraków\n",
        "\n",
        "#import pdb # do debugowania"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uyO444wEeNjl"
      },
      "outputs": [],
      "source": [
        "#test = ImageDataset(TRAIN_DIR, TRAIN_CSV)\n",
        "#sus = test[1][0]\n",
        "#transforms.ToPILImage()(sus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NvcEVfoKeq2I"
      },
      "outputs": [],
      "source": [
        "#test2 = ImageDataset(VALID_DIR, VALID_CSV)\n",
        "#sus2 = test2[-2][0]\n",
        "#transforms.ToPILImage()(sus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bcB9Bd3SfYi-"
      },
      "outputs": [],
      "source": [
        "#sus2.shape, sus2.min(), sus2.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BePGoYG0f1HT",
        "outputId": "ee35d1e6-2207-4238-a31e-e0167b65c1ba"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QJjqZceKCYLy",
        "tags": [
          "Definiowanie modelu"
        ]
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.threshold = 0.006\n",
        "        input_dim=3*128*128\n",
        "\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding='same'), # 128x128x16\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 64x64x16\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding='same'), # 64x64x32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 32x32x32\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding='same'), # 32x32x64\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 16x16x64\n",
        "        )\n",
        "\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16*16*128, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 16*16*128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2), #32x32x32\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2), #64x64x16\n",
        "            #nn.Conv2d(32, 32, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            #nn.Upsample(scale_factor=2),\n",
        "            #nn.Conv2d(32, 3, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2), #128x128x3\n",
        "            nn.Sigmoid(),\n",
        "            #nn.Upsample(scale_factor=2),\n",
        "            #nn.ReLU(),\n",
        "            #nn.ConvTranspose2d(8, 3, kernel_size=2, stride=2), #128x128x3\n",
        "            #nn.Sigmoid() #?\n",
        "        )\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, 500),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, 200),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(200, 500),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, input_dim),\n",
        "            #nn.Sigmoid()\n",
        "        )\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.encoder(x.to(device))\n",
        "        x = self.bottleneck(x)\n",
        "        x = x.view(-1, 128, 16, 16)\n",
        "        x = self.decoder(x)\n",
        "        #x = x.view(-1, 3, 128, 128)\n",
        "        return x\n",
        "\n",
        "    def predict(self, batch: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Przypisz każdemu zdjęciu z batcha 0 lub 1.\n",
        "        Nie zmieniaj ani nie dodawaj argumentów w tej metodzie!\n",
        "        \"\"\"\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        outputs = self.forward(batch)\n",
        "        losses = nn.functional.mse_loss(outputs.view(batch.size(0), - 1), batch.view(batch.size(0), - 1), reduction='none').mean(dim=1)\n",
        "        anomalies = losses > self.threshold\n",
        "\n",
        "        return anomalies\n",
        "\n",
        "\n",
        "def train_model() -> Model:\n",
        "    \"\"\"Stwórz i wytrenuj model\"\"\"\n",
        "    torch.manual_seed(0)\n",
        "    model = Model().to(device)\n",
        "    train_loader = train_dataloader()\n",
        "    valid_loader = valid_dataloader()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(30):\n",
        "      for batch in train_loader:\n",
        "          inputs = batch[0].to(device)\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, inputs)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      #if epoch % 1 == 0:\n",
        "      #    print(f\"{epoch}: loss: {loss.item():.6f}\")\n",
        "\n",
        "    #my_train_model(model, train_loader, valid_loader, 10, optimizer, criterion, True, True)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jqWBVvitp3R"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "model = train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euNEs1EmtbL0"
      },
      "outputs": [],
      "source": [
        "#transforms.ToPILImage()(model(sus[None, :]).view(3, 128, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADzNf1gP87yV"
      },
      "outputs": [],
      "source": [
        "#transforms.ToPILImage()(model(sus2[None, :]).view(3, 128, 128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbjmMLYC3s6b"
      },
      "source": [
        "# Kod z kryterium oceniającym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MyygEopHC_2"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "def grade_solution(model):\n",
        "    dataloader = valid_dataloader() # Podczas sprawdzania podmienimy to na test_dataloader\n",
        "\n",
        "    predictions = np.concatenate([\n",
        "        model.predict(images).cpu().to(dtype=torch.int32).numpy() for images, _ in dataloader\n",
        "    ], axis=0)\n",
        "\n",
        "    labels = np.concatenate([label for _, label in dataloader], axis=0, dtype=np.int32)\n",
        "\n",
        "    accuracy = sum(labels == predictions) / len(labels)\n",
        "\n",
        "    score = min(max(accuracy - 0.6, 0.0), 0.3) / 0.3\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f'Twój wynik to {score} pkt')\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw-WvDDiHSrL"
      },
      "source": [
        "## Ewaluacja wywołana na dostarczonym zbiorze\n",
        "(docelowo będzie uruchomiona na zbiorze testowym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTgtRsQK3slt",
        "tags": [
          "Trenowanie i testowanie"
        ]
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    grade_solution(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gvd5fk3kAfr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "S\n",
        "thresholds = np.arange(0, 0.01, 0.001)\n",
        "score_acc = []\n",
        "score_prec = []\n",
        "score_rec = []\n",
        "\n",
        "validloader = valid_dataloader()\n",
        "for threshold in thresholds:\n",
        "    model.threshold = threshold\n",
        "\n",
        "    predictions = np.concatenate([\n",
        "        model.predict(images).cpu().to(dtype=torch.int32).numpy() for images, _ in validloader\n",
        "    ], axis=0)\n",
        "\n",
        "    labels = np.concatenate([label for _, label in validloader], axis=0, dtype=np.int32)\n",
        "\n",
        "    score_acc.append(accuracy_score(labels, predictions))\n",
        "    score_prec.append(precision_score(labels, predictions))\n",
        "    score_rec.append(recall_score(labels, predictions))\n",
        "\n",
        "plt.plot(thresholds, score_acc, label='accuracy_score')\n",
        "plt.plot(thresholds, score_prec, label='precision_score')\n",
        "plt.plot(thresholds, score_rec, label='recall_score')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcdDAAOMn8Yp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
