{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler, random_split\n",
    "from torchvision import transforms\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensor dataset and a data loader\n",
    "\n",
    "X, y = torch.ones(5, 2), torch.tensor([0, 1, 1, 2, 1])\n",
    "\n",
    "# dataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# sampler\n",
    "class_counts = torch.unique(dataset.tensors[1], return_counts=True)[1]\n",
    "weights = [cnt / len(dataset) for cnt in class_counts]\n",
    "sampler = WeightedRandomSampler(torch.tensor(weights), len(dataset))\n",
    "\n",
    "# data loader\n",
    "dataloader = DataLoader(dataset, batch_size=16, sampler=sampler)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True) # alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "\n",
    "random_split(dataset, [0.3, 0.3, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "\n",
    "class my_set(Dataset):\n",
    "    def __init__(self, length = 100, transform = None):\n",
    "        self.len = length\n",
    "        self.x = torch.ones(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset functionalities\n",
    "\n",
    "my_dataset = my_set()\n",
    "print(my_dataset)\n",
    "print(my_dataset[5])\n",
    "print(len(my_dataset))\n",
    "\n",
    "for x, y in my_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "\n",
    "class add_mult(object):\n",
    "    def __init__(self, addx = 1, muly = 3):\n",
    "        self.addx = addx\n",
    "        self.muly = muly\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        x += self.addx\n",
    "        y *= self.muly\n",
    "        return x, y\n",
    "\n",
    "my_dataset = my_set(transform=add_mult())\n",
    "print(my_dataset[3])\n",
    "\n",
    "def mult(sample):\n",
    "    return sample[0] + 1, sample[1] * 10\n",
    "\n",
    "data_transform = transforms.Compose([add_mult(), mult])\n",
    "print(data_transform(my_dataset[3]))\n",
    "my_dataset = my_set(transform=data_transform)\n",
    "print(my_dataset[3])\n",
    "\n",
    "# sample transformation for images\n",
    "transforms.Compose([transforms.CenterCrop(20), transforms.RandomVerticalFlip(), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "\n",
    "# from dict / array / numpy\n",
    "my_dataset = pd.DataFrame([[50, True], [40, False]])\n",
    "print(my_dataset)\n",
    "my_dataset = pd.DataFrame({ 'col1': [1, 2], 'col2': [3, 4] }, copy=True)\n",
    "print(my_dataset)\n",
    "my_dataset = pd.DataFrame(data=[[1, 2, 3], [4, 5, 6]], columns=['a', 'b', 'c'], index=[3, 'd'])\n",
    "print(my_dataset)\n",
    "\n",
    "# from csv\n",
    "my_dataset = pd.read_csv(os.path.join(\"data\",\"train.csv\"))\n",
    "my_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access elements\n",
    "\n",
    "print(my_dataset.shape, my_dataset.iloc[0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the data - basic info\n",
    "\n",
    "my_dataset.info()\n",
    "my_dataset.describe() # only int values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the data - value counts\n",
    "\n",
    "my_dataset[\"Sex\"].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the data - correlations\n",
    "\n",
    "# you should do that only with train data\n",
    "corr_matrix = my_dataset.corr(numeric_only=True)\n",
    "print(corr_matrix[\"Survived\"].sort_values(ascending=False))\n",
    "corr_matrix # only int values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
