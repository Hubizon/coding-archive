{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "collapsed": true,
        "id": "I6Twuk-bVcdZ",
        "outputId": "060b5a4f-9fc5-48fd-de16-f8380dd04129"
      },
      "outputs": [],
      "source": [
        "%pip install sacremoses\n",
        "\"\"\"\n",
        "%pip install wget\n",
        "\n",
        "import wget\n",
        "url = 'https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt'\n",
        "wget.download(url)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7tSDeAn2Vjz_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fU148tRrWSgv"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TwyCuxJVu09",
        "outputId": "ab658fb9-7c87-4318-a6e4-8d3323f014a4"
      },
      "outputs": [],
      "source": [
        "model = transformers.RobertaForCausalLM.from_pretrained(\"allegro/herbert-klej-cased-v1\", is_decoder=True).to(device)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "veRLzVbZsIqm"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, file_path, block_size=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.block_size = block_size\n",
        "\n",
        "        # Read the file and tokenize\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        # Concatenate all lines into a single string\n",
        "        text = ''.join(lines)\n",
        "\n",
        "        # Tokenize the text and create examples\n",
        "        self.examples = []\n",
        "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
        "        #tokenized_text = tokenizer.encode_plus(text, return_attention_mask=True, return_tensors='pt')[0]\n",
        "        #pdb.set_trace()\n",
        "\n",
        "        for i in range(0, len(tokenized_text) - block_size + 1, 2):\n",
        "            self.examples.append(tokenizer.build_inputs_with_special_tokens(tokenized_text[i:i + block_size]))\n",
        "\n",
        "        #pdb.set_trace()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.tensor(self.examples[i], dtype=torch.long, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-9ZeuZ2WspkU"
      },
      "outputs": [],
      "source": [
        "block_size = 100\n",
        "dataset_train = TextDataset(tokenizer, \"tadeusz_train.txt\", block_size=block_size)\n",
        "dataset_valid = TextDataset(tokenizer, \"tadeusz_valid.txt\", block_size=block_size)\n",
        "dataset_test = TextDataset(tokenizer, \"tadeusz_test.txt\", block_size=block_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Yc0aGr64syMp"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBXUPL8VbPSW",
        "outputId": "5db2dd6b-28e0-4bfd-adf8-92b0125f39fc"
      },
      "outputs": [],
      "source": [
        "def calculate_perplexity(model, tokenizer, inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=inputs, labels=inputs)\n",
        "        loss = outputs.loss\n",
        "\n",
        "    perplexity = torch.exp(loss)\n",
        "    return perplexity.item()\n",
        "\n",
        "def test_perplexity(model, tokenizer, data_loader):\n",
        "    model.eval()\n",
        "    sum, cnt = 0, 0\n",
        "    for batch in data_loader:\n",
        "        batch_size = batch.size(0)\n",
        "        cnt += batch_size\n",
        "        sum += calculate_perplexity(model, tokenizer, batch) * batch_size\n",
        "    return sum / cnt\n",
        "\n",
        "print(test_perplexity(model, tokenizer, valid_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k6ebQCP3eyl3"
      },
      "outputs": [],
      "source": [
        "#pdb.set_trace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr-YfSNWdjz-",
        "outputId": "13865986-4007-4810-8182-12ca8abc8e80"
      },
      "outputs": [],
      "source": [
        "all_token_ids = list(tokenizer.get_vocab().values())\n",
        "special_token_ids = tokenizer.all_special_ids\n",
        "valid_token_ids = [token_id for token_id in all_token_ids if token_id not in special_token_ids]\n",
        "len(valid_token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMcPeQ0OriHv",
        "outputId": "268db449-cc4f-42ac-bfa8-4383ee3796e4"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)\n",
        "\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "lr_scheduler = transformers.get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=300, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "model.train()\n",
        "_iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "  print (f'------ Epoch {epoch} ------')\n",
        "  iter_epoch = 0\n",
        "  for batch in train_loader:\n",
        "    n = batch.size(1)\n",
        "    num = int(0.15 * n)\n",
        "    selected_indices = torch.tensor(np.random.choice(np.arange(n), num, replace=False))\n",
        "    num_left_alone = int(0.2 * num)\n",
        "    indices_left_alone = torch.tensor(np.random.choice(selected_indices, num_left_alone, replace=False))\n",
        "    num_replaced = int(0.1 * num)\n",
        "    indices_replaced = torch.tensor(np.random.choice(indices_left_alone, num_replaced, replace=False))\n",
        "\n",
        "    selected_indices = np.setdiff1d(selected_indices, indices_left_alone)\n",
        "    #indices_left_alone = np.setdiff1d(indices_left_alone, indices_replaced)\n",
        "\n",
        "    inputs = torch.clone(batch)\n",
        "    inputs[:, selected_indices] = tokenizer.mask_token_id\n",
        "    inputs[:, indices_replaced] = torch.tensor(np.random.choice(valid_token_ids, num_replaced, replace=False), device=device)\n",
        "\n",
        "    outputs = model(input_ids=inputs, labels=batch)\n",
        "\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    lr_scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    iter_epoch += 1\n",
        "    _iter += 1\n",
        "\n",
        "    if (iter_epoch % 50 == 0):\n",
        "      print(f'Epoch {epoch} - loss: {loss.item()}, lr: {lr_scheduler._last_lr}, iter: {iter_epoch} / {len(dataset_train) // batch_size}')\n",
        "\n",
        "  print(f'End of epoch {epoch} - loss: {loss.item()}, lr: {lr_scheduler._last_lr}, iter: {_iter} / {len(dataset_train) // batch_size}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "PXv7agsVvpA_",
        "outputId": "18049463-daaf-4fb1-9d3a-d848f78638ce"
      },
      "outputs": [],
      "source": [
        "#input_ids = tokenizer.encode('Pan Tadeusz, choć młodzik, ale prawem gościa\\nWysoko siadł przy damach obok jegomościa;\\nMiędzy nim i stryjaszkiem jedno pozostało\\nPuste miejsce, jak gdyby na kogoś czekało.', return_tensors='pt')\n",
        "#input_ids = tokenizer.encode('Klucznik na to słowo\\nPobladnął, pochylił się, i ciała połową\\nWygięty naprzód, stanął, zwisł na jednej nodze,', return_tensors='pt')\n",
        "input_ids = tokenizer.encode('Jam jest Jacek', return_tensors='pt')\n",
        "output_ids = model.generate(input_ids.to(device), max_length=200)\n",
        "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCl8UkMGvZkT",
        "outputId": "ad4dd0f6-2e45-41d5-d843-c98da35a1b9e"
      },
      "outputs": [],
      "source": [
        "print(test_perplexity(model, tokenizer, valid_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmfN2DJUtzbU"
      },
      "outputs": [],
      "source": [
        "assert False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3l0wHevsWin"
      },
      "outputs": [],
      "source": [
        "#input_ids = tokenizer.encode('Pan Tadeusz, choć młodzik, ale prawem gościa\\nWysoko siadł przy damach obok jegomościa;\\nMiędzy nim i stryjaszkiem jedno pozostało\\nPuste miejsce, jak gdyby na kogoś czekało.', return_tensors='pt')\n",
        "#input_ids = tokenizer.encode('Klucznik na to słowo\\nPobladnął, pochylił się, i ciała połową\\nWygięty naprzód, stanął, zwisł na jednej nodze,', return_tensors='pt')\n",
        "input_ids = tokenizer.encode('Jam jest Jacek', return_tensors='pt', temperature=1)\n",
        "output_ids = model.generate(input_ids.to(device), max_length=200)\n",
        "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p4UkpjvsdZk"
      },
      "outputs": [],
      "source": [
        "print(test_perplexity(model, tokenizer, valid_loader))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
