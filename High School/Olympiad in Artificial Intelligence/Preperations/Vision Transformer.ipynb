{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "alpPV1LyAe5G"
      },
      "outputs": [],
      "source": [
        "# https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial15/Vision_Transformer.html\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import copy\n",
        "\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqRjiFHUAoay",
        "outputId": "5144ee33-96ff-4b49-b39c-b3715ad4f456"
      },
      "outputs": [],
      "source": [
        "dataset_train = torchvision.datasets.CIFAR10(root='./data', download=True, transform=torchvision.transforms.ToTensor(), train=True)\n",
        "dataset_valid = torchvision.datasets.CIFAR10(root='./data', download=True, transform=torchvision.transforms.ToTensor(), train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iS6EobUdWPGa"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DEDiNuHMB8gX"
      },
      "outputs": [],
      "source": [
        "def img_to_patch(x, patch_size):\n",
        "  B, C, H, W = x.shape\n",
        "  x = x.reshape(B, C, H // patch_size, patch_size, W // patch_size, patch_size)\n",
        "  x = x.permute(0, 2, 4, 1, 3, 5) # [B, H', W', C, p_H, p_W]\n",
        "  x = x.flatten(1, 2) # [B, H'*W', C, p_H, p_W]\n",
        "  x = x.flatten(2, 4) # [B, H'*W', C*p_H*p_W]\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6nj5a2IV5-S",
        "outputId": "5b3e5028-d3b9-44a8-860c-5fa8fc6ef058"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "sample_images = next(iter(train_loader))[0].to(device)\n",
        "img_to_patch(sample_images, 4).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p2qSx3KNWylK"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "  def __init__(self, embed_dim, hidden_dim, num_heads, dropout=.0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_norm_1 = nn.LayerNorm(embed_dim)\n",
        "    self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
        "\n",
        "    self.layer_norm_2 = nn.LayerNorm(embed_dim)\n",
        "    self.linear = nn.Sequential(\n",
        "        nn.Linear(embed_dim, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_dim, embed_dim),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    inp_x = self.layer_norm_1(x)\n",
        "    x = x + self.attn(inp_x, inp_x, inp_x)[0]\n",
        "    x = x + self.linear(self.layer_norm_2(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AQx2TgiyXgZd"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "  def __init__(self, embed_dim, hidden_dim, num_channels, num_heads, num_layers,\n",
        "               num_classes, patch_size, num_patches, dropout=.0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.patch_size = patch_size\n",
        "\n",
        "    self.input_layer = nn.Linear(num_channels * (patch_size ** 2), embed_dim)\n",
        "    self.transformer = nn.Sequential(*[AttentionBlock(embed_dim, hidden_dim, num_heads, dropout)\n",
        "                                      for _ in range(num_layers)])\n",
        "    self.mlp_head = nn.Sequential(\n",
        "        nn.LayerNorm(embed_dim),\n",
        "        nn.Linear(embed_dim, num_classes)\n",
        "    )\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "    self.pos_embedding = nn.Parameter(torch.randn(1, 1 + num_patches, embed_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = img_to_patch(x, self.patch_size)\n",
        "    B, T, _ = x.shape\n",
        "    x = self.input_layer(x)\n",
        "\n",
        "    cls_token = self.cls_token.repeat(B, 1, 1)\n",
        "    x = torch.cat([cls_token, x], dim=1)\n",
        "    x = x + self.pos_embedding[:, :T + 1]\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    x = x.transpose(0, 1)\n",
        "    x = self.transformer(x)\n",
        "\n",
        "    cls = x[0]\n",
        "    out = self.mlp_head(cls)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B3WXCmIcXNn",
        "outputId": "63a1fff5-0457-47d7-905b-33d3dbc8c708"
      },
      "outputs": [],
      "source": [
        "model = VisionTransformer(256, 512, 3, 8, 6, 10, 4, 64, .2).to(device)\n",
        "model(sample_images).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "g597VrZoc-hs"
      },
      "outputs": [],
      "source": [
        "# a function to train a model\n",
        "# you may need to convert tensors to float32 (before criterium)\n",
        "# and .to(device)\n",
        "\n",
        "def compute_error(model, data_loader, criterion, c_sum=False):\n",
        "    model.eval()\n",
        "    losses, num_of_el = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            if not c_sum: loss *= len(y)\n",
        "            losses += loss\n",
        "            num_of_el += len(y)\n",
        "    return losses / num_of_el\n",
        "\n",
        "\n",
        "def train_model(model: nn.Module,\n",
        "              train_loader: DataLoader,\n",
        "              valid_loader: DataLoader,\n",
        "              num_epochs: int,\n",
        "              optimizer: torch.optim.Optimizer,\n",
        "              criterion,\n",
        "              verbose: bool = True,\n",
        "              verbose_plot: bool = False\n",
        "              ) -> float:\n",
        "\n",
        "    best_epoch = None\n",
        "    best_params = None\n",
        "    best_val_loss = np.inf\n",
        "    train_losses, valid_losses = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        _iter = 1\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if verbose:\n",
        "                if _iter % 100 == 0:\n",
        "                    print(f\"Minibatch {_iter:>6}    |  loss {loss.item():>5.2f}  |\")\n",
        "            _iter += 1\n",
        "\n",
        "        val_loss = compute_error(model, valid_loader, criterion)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_epoch = epoch\n",
        "            best_val_loss = val_loss\n",
        "            best_params = [copy.deepcopy(p.detach().cpu()) for p in model.parameters()]\n",
        "\n",
        "        if verbose:\n",
        "            clear_output(True)\n",
        "            m = f\"After epoch {epoch:>2} | valid loss: {val_loss:>5.2f}\"\n",
        "            print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n",
        "\n",
        "        if verbose_plot:\n",
        "            train_loss = compute_error(model, train_loader, criterion)\n",
        "            train_losses.append(train_loss.detach().cpu())\n",
        "            valid_losses.append(val_loss.detach().cpu())\n",
        "\n",
        "    if best_params is not None:\n",
        "        if verbose:\n",
        "            print(f\"\\nLoading best params on validation set in epoch {best_epoch} with loss {best_val_loss:.2f}\")\n",
        "        with torch.no_grad():\n",
        "            for param, best_param in zip(model.parameters(), best_params):\n",
        "                param[...] = best_param\n",
        "\n",
        "    if verbose_plot:\n",
        "        plt.figure(figsize=(6, 3))\n",
        "        plt.plot(train_losses, c='b', label='train')\n",
        "        plt.plot(valid_losses, c='r', label='valid')\n",
        "        plt.grid(ls=':')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    return best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "--gkStbJdUlD",
        "outputId": "9a2cc92b-39b2-4fef-adee-89daacf88ead"
      },
      "outputs": [],
      "source": [
        "n_epochs = 5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_model(model, train_loader, valid_loader, n_epochs, optimizer, criterion, True, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL04YusudwQq",
        "outputId": "9f761add-2922-4ab8-f7fe-a38eb8fba068"
      },
      "outputs": [],
      "source": [
        "def accuracy_multiple(outputs, y):\n",
        "    pred = outputs.argmax(dim=1)\n",
        "    return sum(pred == y)\n",
        "\n",
        "print(compute_error(model, valid_loader, accuracy_multiple, c_sum=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0I-qQ33frRn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
