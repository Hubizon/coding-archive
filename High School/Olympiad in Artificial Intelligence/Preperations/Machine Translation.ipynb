{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ziPSx7oTzn"
      },
      "source": [
        "# Tłumaczenia maszynowe\n",
        "\n",
        "W dzisiejszym konkursie Waszym zadaniem będzie implementacja metody opisanej w pracy \"Naural machine translation by jointly learning to align and translate\". Otrzymacie punkty za implementację i trening modelu, policzenie odpowiednich metryk oraz przeprowadzenie dodatkowych eksperymentów i wizualizacji. W czasie pracy powinniście zadbać o jasność i czytelność kodu, a także estetykę prezentowanych wykresów. Wasza implementacja będzie oceniana pod kątem zgodności z publikacją.\n",
        "\n",
        "## Zasady konkursu\n",
        "\n",
        "Musicie przestrzegać poniższych zasad:\n",
        "\n",
        "- Nie wolno korzystać z Internetu. Wyjątki to OpenAI API, dokumentacja Pytorcha, a także Google Classroom Olimpiady.\n",
        "- Nie wolno korzystać z Copilota, ani żadnych innych modeli pomagających pisać kod, poza modelami z rodziny GPT3.5.\n",
        "- Nie wolno korzystać z własnych notatek: zarówno odręcznych, jak i plików na komputerze (wliczając w to w szczególności kod pobrany na komputer).\n",
        "- Nie wolno łączyć się z zasobami obliczeniowymi innymi niż Google Colab z T4 GPU.\n",
        "\n",
        "## Zadanie i punktacja\n",
        "\n",
        "Modele będziesz trenować na zbiorze danych zawierającym pary zdań w języku angielskim i niemieckim (*parallel corpus*). Pamiętajcie o dobrych praktykach pisania kodu i poprawnym formatowaniu, będzie to wpływało na ocenę. Na podstawie załączonej pracy wykonaj następujące podzadania.\n",
        "\n",
        "**Podzadanie 1: Implementacja modelu (7 p.)**\n",
        "\n",
        "W tej sekcji prosimy o bardzo dokładne zaimplementowanie metody z pracy.\n",
        "\n",
        "**Podzadanie 2: Trening modelu (3 p.)**\n",
        "\n",
        "Wytrenuj model na dostarczonym zbiorze danych (w startowym kodzie są już zaimplementowane dataloadery). Podczas treningu zadbaj o monitorowanie zarówno lossu treningowego jak i walidacyjnego. Następnie sporządź wykresy tych lossów w zależności od iteracji. Wykonaj ewaluację wytrenowanego modelu na podzbiorze testowym dostarczonego zbioru używając właściwych metryk. Możesz skorzystać z metryk wykorzystanych w pracy. Zaprezentuj przykłady zarówno poprawnych jak i niepoprawnych tłumaczeń.\n",
        "\n",
        "**Podzadanie 3: Wizualizacja atencji (1 p.)**\n",
        "\n",
        "Zaprezentuj wizualizacje wyuczonych map atencji na przykładzie ciekawych zdań. Możesz wzorować się na wykresach z pracy.\n",
        "\n",
        "**Podzadanie 4: Dodatkowe eksperymenty (2 p.)**\n",
        "\n",
        "Jeśli masz pomysły na dodatkowe interesujące eksperymenty, możesz dostać za nie dodatkowe punkty. Możesz rozważyć modyfikacje modelu, ablacje i inne.\n",
        "\n",
        "## Uwagi\n",
        "* Możesz zmieniać sygnatury funkcji i klas, a także zaproponowaną przez nas poniżej strukturę kodu. Pamiętaj jednak o dobrych praktykach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4qoj7EReh4X"
      },
      "source": [
        "## Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCdiVJwsp-yE",
        "outputId": "0674d2e1-1c6e-43a5-a878-085d3c8d7c2c"
      },
      "outputs": [],
      "source": [
        "! pip install datasets\n",
        "! pip install evaluate\n",
        "! pip install torchtext\n",
        "\n",
        "# Download the embedding models\n",
        "! python -m spacy download en_core_web_sm\n",
        "! python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1T3Q01mUoTzp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import datasets\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
        "import torchtext.vocab; torchtext.disable_torchtext_deprecation_warning()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CjnDgGz1r4xB"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "seed = 1234\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrLxNJhf2yr9"
      },
      "source": [
        "## Datasety\n",
        "\n",
        "Przygotowaliśmy dla Ciebie dataloadery oraz tokenizatory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0arLiXcBsNSX"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
        "\n",
        "en_nlp = spacy.load(\"en_core_web_sm\")\n",
        "de_nlp = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "\n",
        "\n",
        "def tokenize_example(example, max_length=1000):\n",
        "    en_tokens = [token.text.lower() for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
        "    de_tokens = [token.text.lower() for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
        "\n",
        "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
        "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
        "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n",
        "\n",
        "\n",
        "train_data = dataset[\"train\"].map(tokenize_example)\n",
        "valid_data = dataset[\"validation\"].map(tokenize_example)\n",
        "test_data = dataset[\"test\"].map(tokenize_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "au23DDqN1fhn"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "min_freq = 2\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "\n",
        "special_tokens = [unk_token, pad_token, sos_token, eos_token]\n",
        "\n",
        "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "    train_data[\"en_tokens\"],\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")\n",
        "\n",
        "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "    train_data[\"de_tokens\"],\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")\n",
        "\n",
        "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
        "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
        "\n",
        "unk_index = en_vocab[unk_token]\n",
        "pad_index = en_vocab[pad_token]\n",
        "\n",
        "en_vocab.set_default_index(unk_index)\n",
        "de_vocab.set_default_index(unk_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "diJPcDDC1laQ"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def numericalize_example(example):\n",
        "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
        "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
        "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}\n",
        "\n",
        "train_data = train_data.map(numericalize_example)\n",
        "valid_data = valid_data.map(numericalize_example)\n",
        "test_data = test_data.map(numericalize_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i5A9pH_s1oRb"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "format_columns = [\"en_ids\", \"de_ids\"]\n",
        "\n",
        "train_data = train_data.with_format(\n",
        "    type=\"torch\", columns=format_columns, output_all_columns=True\n",
        ")\n",
        "\n",
        "valid_data = valid_data.with_format(\n",
        "    type=\"torch\",\n",
        "    columns=format_columns,\n",
        "    output_all_columns=True,\n",
        ")\n",
        "\n",
        "test_data = test_data.with_format(\n",
        "    type=\"torch\",\n",
        "    columns=format_columns,\n",
        "    output_all_columns=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6v4-rqCR1sXX"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
        "    def collate_fn(batch):\n",
        "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
        "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
        "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
        "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
        "        batch = {\n",
        "            \"en_ids\": batch_en_ids,\n",
        "            \"de_ids\": batch_de_ids,\n",
        "        }\n",
        "        return batch\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=shuffle,\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "train_data_loader = get_data_loader(train_data, BATCH_SIZE, pad_index, shuffle=True)\n",
        "valid_data_loader = get_data_loader(valid_data, BATCH_SIZE, pad_index)\n",
        "test_data_loader = get_data_loader(test_data, BATCH_SIZE, pad_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBf02Fb_oGUB"
      },
      "source": [
        "## Podzadanie 1: Implementacja modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IAW0DvEWqNb3"
      },
      "outputs": [],
      "source": [
        "# Hubert Jastrzebski\n",
        "# V LO Kraków\n",
        "\n",
        "import torch.nn.functional as F\n",
        "#import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M-tOQlE91tgh"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.encoder_hidden_dim = encoder_hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        outputs = outputs[:, :, self.encoder_hidden_dim:]\n",
        "\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PUZnrF61NhfK"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
        "        super().__init__()\n",
        "        self.encoder_hidden_dim = encoder_hidden_dim\n",
        "\n",
        "        self.attn = nn.Linear(2 * encoder_hidden_dim, encoder_hidden_dim)\n",
        "        self.va = nn.Linear(encoder_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        seq_len = encoder_outputs.size(0)\n",
        "\n",
        "        energy = torch.tanh(self.attn(hidden).unsqueeze(0).expand(seq_len, -1, -1) + encoder_outputs)\n",
        "        attention = F.softmax(self.va(energy).squeeze(), dim=0)\n",
        "        result = torch.bmm(attention.transpose(0, 1).unsqueeze(1), encoder_outputs.transpose(0, 1)).squeeze()\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LIQ7dt3T1x9X"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        output_dim,\n",
        "        embedding_dim,\n",
        "        encoder_hidden_dim,\n",
        "        decoder_hidden_dim,\n",
        "        dropout,\n",
        "        attention,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.decoder_hidden_dim = decoder_hidden_dim\n",
        "\n",
        "        self.attention = attention\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.rnn = nn.GRU(encoder_hidden_dim + embedding_dim, decoder_hidden_dim, bidirectional=True)\n",
        "        self.fc_out = nn.Linear(2 * encoder_hidden_dim + decoder_hidden_dim + embedding_dim, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        attention = self.attention(hidden, encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, attention), dim=1).unsqueeze(0)\n",
        "\n",
        "        hidden = hidden.unsqueeze(0)\n",
        "        hidden = torch.cat((hidden[:,:,self.decoder_hidden_dim:], hidden[:,:,:self.decoder_hidden_dim]), dim=0)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "\n",
        "        output = torch.cat((embedded, attention, output.squeeze()), dim=1)\n",
        "        prediction = self.fc_out(output)\n",
        "\n",
        "        return prediction, hidden, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PmIZI0uf1zlk"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        input = trg[0]\n",
        "        outputs = torch.zeros(trg.shape[0], trg.shape[1], self.decoder.output_dim, device=device)\n",
        "\n",
        "        for t in range(1, trg.shape[0]):\n",
        "            prediction, hidden, attention = self.decoder(input, hidden, encoder_outputs)\n",
        "            outputs[t] = prediction\n",
        "            input = trg[t]\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uh5onzBK102Z"
      },
      "outputs": [],
      "source": [
        "input_dim = len(de_vocab)\n",
        "output_dim = len(en_vocab)\n",
        "encoder_embedding_dim = 256\n",
        "decoder_embedding_dim = 256\n",
        "encoder_hidden_dim = 512\n",
        "decoder_hidden_dim = 512\n",
        "encoder_dropout = 0.5\n",
        "decoder_dropout = 0.5\n",
        "\n",
        "attention = Attention(encoder_hidden_dim, decoder_hidden_dim).to(device)\n",
        "encoder = Encoder(input_dim,\n",
        "    encoder_embedding_dim,\n",
        "    encoder_hidden_dim,\n",
        "    decoder_hidden_dim,\n",
        "    encoder_dropout\n",
        ").to(device)\n",
        "decoder = Decoder(\n",
        "    output_dim,\n",
        "    decoder_embedding_dim,\n",
        "    encoder_hidden_dim,\n",
        "    decoder_hidden_dim,\n",
        "    decoder_dropout,\n",
        "    attention,\n",
        ").to(device)\n",
        "model = Seq2Seq(encoder, decoder).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1z-4zdbp30Q"
      },
      "source": [
        "## Podzadanie 2: Trening modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "g9hfo2ETeh4f",
        "outputId": "40d8bb89-bd70-45f1-dccc-eb71461a04e7"
      },
      "outputs": [],
      "source": [
        "# TO!DO: Napisz pętlę treningową. Pamiętaj o zbieraniu statystyk treningowych i walidacyjnych.\n",
        "\n",
        "def compute_loss(model, criterion, data_loader):\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "    average_loss = total_loss / total_samples\n",
        "\n",
        "    return average_loss\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    opimizer,\n",
        "    criterion,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    num_epochs,\n",
        "    verbose=True,\n",
        "    plot=True\n",
        "):\n",
        "    train_losses, valid_losses = [], []\n",
        "    max_norm = 1.0\n",
        "    for epoch in range(num_epochs):\n",
        "        for data in train_loader:\n",
        "            model.train()\n",
        "            src, trg = data['en_ids'], data['de_ids']\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(src, trg)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            val_loss = compute_loss(model, valid_loader, criterion)\n",
        "            valid_losses.append(val_loss)\n",
        "\n",
        "    return train_losses, valid_losses\n",
        "\n",
        "# TO!DO: Wytrenuj model na dostarczonym zbiorze danych\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.95, eps=1e-6)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_losses, valid_losses = train_model(model, optimizer, criterion, train_data_loader, valid_data_loader, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP72PALSeh4f"
      },
      "outputs": [],
      "source": [
        "# TO!DO: Sporządź wykresy funkcji kosztu\n",
        "\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(valid_losses, label='valid')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6vTMnR2eh4f"
      },
      "outputs": [],
      "source": [
        "# TO!DO: Zewaluuj model na zbiorze testowym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LcnWDQSeh4f"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(sentence, model):\n",
        "    en_tokens = []  # Initialize list for English tokens\n",
        "    de_tokens = []  # Initialize list for German tokens\n",
        "    attention = []  # Initialize list for attention scores\n",
        "\n",
        "    # Tokenize the input sentence\n",
        "    input_tensor = model.source_vocab.get_ids_from_sentence(sentence)\n",
        "    input_length = len(input_tensor)\n",
        "    input_tensor = torch.LongTensor(input_tensor).unsqueeze(1).to(model.device)\n",
        "\n",
        "    # Pass the input through the model to get the output and attention\n",
        "    with torch.no_grad():\n",
        "        output, attn = model(input_tensor)\n",
        "\n",
        "    # Get the predicted token IDs and attention scores\n",
        "    output_ids = output.argmax(dim=2)\n",
        "    attention_scores = attn.squeeze(1)\n",
        "\n",
        "    for i in range(output_ids.size(0)):\n",
        "        en_tokens.append(model.target_vocab.get_token(output_ids[i].item()))\n",
        "        de_tokens.append(model.source_vocab.get_token(input_tensor[i].item()))\n",
        "        attention.append(attention_scores[i].tolist())\n",
        "\n",
        "    return en_tokens, de_tokens, attention\n",
        "\n",
        "\n",
        "# TO!DO: Przykłady tłumaczeń"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsaqgex5eh4f"
      },
      "source": [
        "## Podzadanie 3: Wizualizacja atencji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaBRU1_q2FJL"
      },
      "outputs": [],
      "source": [
        "def plot_attention(sentence, translation, attention):\n",
        "    pass\n",
        "    # TO!DO\n",
        "\n",
        "\n",
        "# TO!DO: Wizualizacja atencji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNxrBZ2Reh4g"
      },
      "source": [
        "## Podzadanie 4: Dodatkowe eksperymenty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBxCe1eXeh4g"
      },
      "outputs": [],
      "source": [
        "# TO!DO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
