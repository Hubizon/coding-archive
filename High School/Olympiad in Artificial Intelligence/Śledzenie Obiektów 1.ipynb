{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2szhiq0QJ4Ek"
      },
      "source": [
        "# Śledzenie obiektów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wstęp\n",
        "W erze cyfrowej, w obliczu rosnącej lawinowo ilości danych wideo, zdolność do ich automatycznego rozpoznawania i interpretowania staje się kluczowa w wielu dziedzinach – od bezpieczeństwa publicznego po autonomiczne pojazdy. Technologie oparte na głębokim uczeniu rewolucjonizują sposób, w jaki przetwarzamy informacje wizualne. Kluczowym wyzwaniem jest tu detekcja i śledzenie obiektów na filmach wideo.\n",
        "\n",
        "Celem tego zadania jest opracowanie algorytmu, który będzie w stanie analizować sekwencje ruchów w grze \"trzy kubki\". Uczestnicy mają za zadanie określić końcową pozycję kubków po serii ruchów, korzystając z analizy statycznych obrazów z każdej klatki nagrania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "# Poniższe funkcje ułatwiają pracę z dostarczonymi danymi\n",
        "# W kolejnych komórkach zobaczysz przykłady ich użycia\n",
        "from utils.utils import get_level_info, get_video_data, display_video, download_and_replace_data\n",
        "\n",
        "FINAL_EVALUATION_MODE = False\n",
        "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
        "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!\n",
        "\n",
        "images, coordinates, target, path_to_images = get_video_data(level=1,video_id=0,dataset=\"example\")\n",
        "display_video(images,rescale=0.7,FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si4Rs-ZqfMfG"
      },
      "source": [
        "## Zadanie 1: Gra w trzy kubki\n",
        "\n",
        "Jedną z możliwości podejścia do problemu rozpoznawania obiektów na wideo jest zastosowanie modelu dedykowanego do analizy statycznych obrazów dla każdej z klatek. To właśnie będziemy starali się tutaj osiągnąć. Dla każdej klatki w animacjach dostarczyliśmy przewidziany przez model opis tego, w których miejscach znajdują się kubki. Na nagraniach pokazane jest jak są zamieniane miejscami. Twoim zadaniem będzie określenie pozycji, na którą finalnie trafią. Oznaczymy ustawienie początkowe jako $[0,1,2]$ licząc w kolejności od lewej do prawej (po współrzędej `x`). Jeżeli następnie przestawimy pierwszy od lewej kubek na przeciwległy koniec, uzyskamy $[1,2,0]$.\n",
        "\n",
        "Będziesz miał dostęp zarówno do wszystkich klatek animacji, jak i do oznaczonych przez nas prostokątów ograniczających, w których znajdują się kubki. Co ważne, algorytm, który będziesz tworzył ma korzystać jedynie z informacji o prostokątach ograniczających. W tym zadaniu, klatki wideo są dostarczone jedynie do wizualizacji przykładów i algorytmu, na własne potrzeby.\n",
        "\n",
        "Punkty za to zadanie będą przyznane za osiągnięcie jak najdokładniejszych predykcji na zbiorze testowym. Kryterium będzie *accuracy*. Ewaluacja na zbiorze testowym będzie dokonana przez organizatorów.\n",
        "\n",
        "## Pliki zgłoszeniowe\n",
        "Tylko ten notebook zawierający **kod** oraz **krótki raport** opisujący Twoje rozwiązanie (do 300 słów). Miejsce na raport znajdziesz na końcu tego notebooka.\n",
        "\n",
        "## Ograniczenia\n",
        "- Twoja funkcja powinna zwracać predykcje w maksymalnie 5 minut używając Google Colab bez GPU.\n",
        "\n",
        "## Uwagi i wskazówki\n",
        "- Testuj swoje rozwiązanie na zbiorze plików wideo `level_1`.\n",
        "- **Skuteczność modelu**: przetestuj skuteczność modelu na zbiorze walidacyjnym używając dostarczonej przez nas funkcji **submission_script**, umieść ten wynik w raporcie.\n",
        "\n",
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` możesz upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających.\n",
        "\n",
        "Za to podzadanie możesz zdobyć pomiędzy 0 i 0.5 punktów. Zdobędziesz 0 punktów jeśli Twoje accuracy na zbiorze testowym będzie poniżej 50%. Jeśli będzie równe 100%, otrzymasz 0.5 punktu. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością metryki."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Poniższe biblioteki są wystarczające do wykonania wszystkich zadań\n",
        "# Jeśli jednak chcesz użyć innych, sprawdź czy są dostępne na serwerze (requirements.txt)\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import IPython.display\n",
        "import json\n",
        "import PIL\n",
        "import sklearn as sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funkcja pomocnicza do ładowania danych\n",
        "images, _, _, _ = get_video_data(level=1,video_id=0,dataset=\"example\")\n",
        "\n",
        "with open(os.path.join(os.getcwd(),'example_tracks','tracks_1_0.json'), 'r') as f:\n",
        "    tracks = json.load(f)\n",
        "\n",
        "for key in tracks.keys():\n",
        "    tracks[key] = [tuple(el) for el in tracks[key]]\n",
        "\n",
        "# Funkcja pomocnicza do wyświetlania danych\n",
        "display_video(images,\n",
        "                tracks=tracks,\n",
        "                rescale=0.7,\n",
        "                FINAL_EVALUATION_MODE=FINAL_EVALUATION_MODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pobieranie danych do podzadań 1, 2 i 3 (około ~646Mb), skrypt będzie wykonywał się parę minut\n",
        "# Wystarczy, że pobierzesz dane tylko raz. Na serwerze sprawdzającym dane będą już pobrane\n",
        "# Struktura plików będzie identyczna jak tutaj\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    download_and_replace_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Funkcja pomocnicza do testowania algorytmu\n",
        "def submission_script(algorithm,level,verbose=False,dataset=\"valid\"):\n",
        "    num_videos, _ = get_level_info(level=level,dataset=dataset)\n",
        "    correct = []\n",
        "    exception_messages = set()\n",
        "    for video_number in range(num_videos):\n",
        "        _, coordinates, target, _ = get_video_data(level=level,video_id=video_number,dataset=dataset)\n",
        "        try:\n",
        "            prediction = algorithm(coordinates)\n",
        "            if tuple(target) == tuple(prediction):\n",
        "                correct.append(1)\n",
        "            else:\n",
        "                correct.append(0)\n",
        "            if verbose:\n",
        "                print(f\"Video: animation_{str(video_number).zfill(4)}\")\n",
        "                print(f\"Prediction: {prediction}\")\n",
        "                print(f\"Target:     {target}\")\n",
        "                print(f\"Score: {tuple(target) == tuple(prediction)}\", end='\\n\\n')\n",
        "        except Exception as e:\n",
        "            correct.append(0)\n",
        "            exception_messages.add(str(e))\n",
        "    if verbose:\n",
        "        print(f\"Accuracy: {np.mean(correct)}\")\n",
        "        print(f\"Correctness: {correct}\")\n",
        "    return np.sum(correct) / num_videos, correct, exception_messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twoje rozwiązanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hubert Jastrzębski - V LO Kraków\n",
        "\n",
        "from itertools import permutations \n",
        "from statistics import median\n",
        "from copy import deepcopy\n",
        "import math\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distance(a, b):\n",
        "    return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
        "\n",
        "def your_algorithm_task_1(coordinates): # nie zmieniaj nazwy funkcji\n",
        "    points = [[((xa + xb) / 2, (ya + yb) / 2) for (xa, ya, xb, yb) in coordinates[name]] for name in coordinates]\n",
        "    points[0].sort()\n",
        "\n",
        "    for i in range(1, len(points)):\n",
        "        p, prev_p = deepcopy(points[i]), deepcopy(points[i - 1])\n",
        "        best_perm = [0, 1, 2]\n",
        "        best_dist = math.inf\n",
        "        \n",
        "        for perm in list(permutations([0, 1, 2])):\n",
        "            p_temp = [p[j] for j in perm]\n",
        "            dist = sum(distance(prev_p[j], p_temp[j]) for j in [0, 1, 2])\n",
        "\n",
        "            if dist < best_dist:\n",
        "                best_dist = dist\n",
        "                best_perm = perm\n",
        "\n",
        "        points[i] = [points[i][j] for j in best_perm]\n",
        "\n",
        "    rp = [points[-1][i][0] for i in [0, 1, 2]]\n",
        "    res = [rp.index(i) for i in [min(rp), median(rp), max(rp)]]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sprawdź jak działa Twój algorytm\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    accuracy, correctness, _ = submission_script(\n",
        "        algorithm=your_algorithm_task_1,\n",
        "        level=1,\n",
        "        verbose=True,\n",
        "        dataset=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zapisz swój raport do zmiennej poniżej, abyśmy mogli go później automatycznie odczytać sprawdzaczką\n",
        "raport_1 = \\\n",
        "\"\"\"\n",
        "Raport z zadania:\n",
        "zamieniam współrzędne prostokątów na ich środki\n",
        "rozpatruję po kolei klatki\n",
        "dla każdej klatki patrzę która permutacja środków daje najmniejszą sumę odległości\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
